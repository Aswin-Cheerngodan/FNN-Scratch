{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "    def __init__(self,inputnodes,hiddennodes,outputnodes,learning_rate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        self.wih = np.random.normal(0.0,pow(self.hnodes,-0.5),(self.hnodes,self.inodes))\n",
    "        self.who = np.random.normal(0.0,pow(self.onodes,-0.5,(self.onodes,self.hnodes)))\n",
    "\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "\n",
    "    def train(self,input_list,target_list):\n",
    "        inputs = np.array(input_list,ndmin=2).T\n",
    "        targets = np.array(target_list,ndmin=2).T\n",
    "\n",
    "        hidden_inputs = np.dot(self.wih,inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        final_inputs = np.dot(self.who,hidden_inputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        output_errors = targets - final_outputs \n",
    "        hidden_errors = np.dot(self.who.T,output_errors)\n",
    "\n",
    "        self.who += self.lr*np.dot((output_errors*final_outputs*(1-final_outputs)),np.transpose(hidden_inputs))\n",
    "        self.wih += self.lr*np.dot((hidden_errors*hidden_outputs*(1-hidden_outputs)),np.transpose(inputs))\n",
    "\n",
    "\n",
    "    def query(self,inputs_list):\n",
    "        inputs = np.array(inputs_list,ndmin=2).T\n",
    "\n",
    "        hidden_inputs = np.dot(self.wih,inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        final_inputs = np.dot(self.who,hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        return final_outputs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self,inputnodes,hiddennodes,outputnodes,learning_rate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        self.wih = np.random.normal(0.0,pow(self.hnodes,-0.5),(self.hnodes,self.inodes))\n",
    "        self.bih = np.zeros((self.hnodes,1))\n",
    "    \n",
    "        self.who = np.random.normal(0.0,pow(self.onodes,-0.5),(self.onodes,self.hnodes))\n",
    "        self.bho = np.zeros((self.onodes,1))\n",
    "\n",
    "    def forward(self,X):\n",
    "        hidden_inputs = np.dot(self.wih,X)+self.bih\n",
    "        hidden_outputs = self.activation(hidden_inputs)\n",
    "\n",
    "        final_inputs = np.dot(self.who,hidden_outputs)+self.bho\n",
    "        final_outputs = self.activation(final_inputs)\n",
    "\n",
    "        return final_outputs\n",
    "    \n",
    "    def backprop(self,X,y):\n",
    "        hidden_inputs = np.dot(self.wih,X)+self.bih\n",
    "        hidden_outputs = self.activation(hidden_inputs)\n",
    "\n",
    "        final_inputs = np.dot(self.who,X)+self.bih\n",
    "        final_outputs = self.activation(final_inputs)\n",
    "\n",
    "        output_error = y-final_outputs\n",
    "        hidden_errors = np.dot(self.who.T,output_error)\n",
    "\n",
    "        self.who += self.lr*np.dot((output_error*final_outputs*(1-final_outputs)),np.transpose(hidden_inputs))\n",
    "        self.bho += self.lr*np.sum((output_error*final_outputs(1-final_outputs)),axis=1,keepdims=True)\n",
    "\n",
    "        self.wih += self.lr*np.dot((hidden_errors*hidden_outputs*(1-hidden_outputs)),np.transpose(X.T))\n",
    "        self.bih += self.lr*np.sum((hidden_errors*hidden_outputs(1-hidden_outputs)),axis=1,keepdims=True)\n",
    "\n",
    "\n",
    "        return np.sum(output_error**2)\n",
    "\n",
    "\n",
    "    def activation(self,z):\n",
    "        return 1/(1+(np.exp(-z)))\n",
    "    \n",
    "\n",
    "    def fit(self,X_train,y_train,n_iter):\n",
    "        past_error = 0\n",
    "        for i in range(n_iter):\n",
    "            error = self.backprop(X_train,y_train)\n",
    "\n",
    "            if abs(past_error-error)<0.01:\n",
    "                break\n",
    "            past_error = error\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        return self.forward(X_test)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flateten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.4040\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.1053\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0720\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0536\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9865 - loss: 0.0429\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0807\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train,epochs=5,batch_size=32)\n",
    "\n",
    "test_loss,test_acc = model.evaluate(X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML FD3\\dl_env\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8792 - loss: 0.4164\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9681 - loss: 0.1078\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.0669\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0512\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0393\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9722 - loss: 0.0933\n",
      "\n",
      "Test Accuracy: 0.98\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Prediction for test image 0: 7 (True label: 7)\n",
      "Prediction for test image 1: 2 (True label: 2)\n",
      "Prediction for test image 2: 1 (True label: 1)\n",
      "Prediction for test image 3: 0 (True label: 0)\n",
      "Prediction for test image 4: 4 (True label: 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),  # Flatten 28x28 images to 1D\n",
    "    Dense(128, activation='relu'),  # Fully connected layer with 128 neurons\n",
    "    Dense(64, activation='relu'),   # Another dense layer with 64 neurons\n",
    "    Dense(10, activation='softmax') # Output layer for 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "# Predict on a few test samples\n",
    "predictions = model.predict(x_test[:5])\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"Prediction for test image {i}: {np.argmax(prediction)} (True label: {y_test[i]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
